{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f972f82d",
   "metadata": {},
   "source": [
    "### Basic working of Google Palm LLM in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c05ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Using cached google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.1 (from google-generativeai)\n",
      "  Using cached google_ai_generativelanguage-0.6.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (2.18.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (2.125.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (2.26.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (4.23.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (2.7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (4.9.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-ai-generativelanguage==0.6.1->google-generativeai) (1.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from pydantic->google-generativeai) (2.18.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.1->google-generativeai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.1->google-generativeai) (1.62.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\anurag\\\\miniconda3\\\\envs\\\\rl_course\\\\lib\\\\site-packages\\\\grpcio-1.60.0.dist-info\\\\METADATA'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.1 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.125.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (2.26.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (4.23.4)\n",
      "Collecting pydantic (from google-generativeai)\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "     ---------------------------------------- 0.0/103.4 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/103.4 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/103.4 kB ? eta -:--:--\n",
      "     ------------------------------------ 103.4/103.4 kB 854.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-generativeai) (4.9.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.1->google-generativeai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->google-generativeai)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic->google-generativeai)\n",
      "  Downloading pydantic_core-2.18.1-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.1->google-generativeai) (1.60.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.1->google-generativeai)\n",
      "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.11.17)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.1->google-generativeai)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Downloading google_generativeai-0.5.0-py3-none-any.whl (142 kB)\n",
      "   ---------------------------------------- 0.0/142.1 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 133.1/142.1 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 142.1/142.1 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.6.1-py3-none-any.whl (663 kB)\n",
      "   ---------------------------------------- 0.0/663.6 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 122.9/663.6 kB 3.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 450.6/663.6 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  655.4/663.6 kB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 663.6/663.6 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "   ---------------------------------------- 0.0/138.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 138.3/138.3 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-2.125.0-py2.py3-none-any.whl (12.5 MB)\n",
      "   ---------------------------------------- 0.0/12.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.5 MB 8.5 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.9/12.5 MB 9.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.4/12.5 MB 9.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.0/12.5 MB 10.8 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.6/12.5 MB 10.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.6/12.5 MB 11.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.8/12.5 MB 9.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.8/12.5 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.3/12.5 MB 7.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.7/12.5 MB 7.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.3/12.5 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.8/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.5/12.5 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.0/12.5 MB 9.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.6/12.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.2/12.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.5 MB 9.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.5/12.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.1/12.5 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.8/12.5 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.3/12.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.9/12.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.5 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.5/12.5 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "   ---------------------------------------- 0.0/407.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 407.9/407.9 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.1-cp310-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.9 MB 17.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 14.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.7/1.9 MB 13.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 11.1 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 229.1/229.1 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.9/96.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.8/48.8 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.62.1-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.6/3.8 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 12.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.4/3.8 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.8/3.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 10.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 10.1 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, pydantic-core, proto-plus, httplib2, grpcio, googleapis-common-protos, annotated-types, pydantic, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.60.0\n",
      "    Uninstalling grpcio-1.60.0:\n",
      "      Successfully uninstalled grpcio-1.60.0\n",
      "Successfully installed annotated-types-0.6.0 google-ai-generativelanguage-0.6.1 google-api-core-2.18.0 google-api-python-client-2.125.0 google-auth-httplib2-0.2.0 google-generativeai-0.5.0 googleapis-common-protos-1.63.0 grpcio-1.60.0 grpcio-status-1.62.1 httplib2-0.22.0 proto-plus-1.23.0 pydantic-2.7.0 pydantic-core-2.18.1 uritemplate-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7899c73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.29-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.4-cp310-cp310-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
      "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
      "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.47-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from langchain) (2.7.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.0-cp310-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.7/50.7 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "   ---------------------------------------- 0.0/817.7 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 112.6/817.7 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 286.7/817.7 kB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 491.5/817.7 kB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 604.2/817.7 kB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 737.3/817.7 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 817.7/817.7 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.4-cp310-cp310-win_amd64.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.5 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 245.8/370.5 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  368.6/370.5 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 370.5/370.5 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/1.9 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.6/1.9 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/1.9 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.3/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.5 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 143.4/287.5 kB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 256.0/287.5 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 287.5/287.5 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.47-py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.0 kB ? eta -:--:--\n",
      "   ---------------------------------------  112.6/113.0 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 113.0/113.0 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.29-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/2.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/2.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/2.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.2/2.1 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.0/2.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.4/50.4 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp310-cp310-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.3 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 143.4/292.3 kB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 276.5/292.3 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 292.3/292.3 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.0-cp310-none-win_amd64.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 112.6/139.2 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.2/139.2 kB 2.1 MB/s eta 0:00:00\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.4/76.4 kB 2.1 MB/s eta 0:00:00\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, orjson, mypy-extensions, multidict, marshmallow, jsonpatch, greenlet, frozenlist, async-timeout, yarl, typing-inspect, SQLAlchemy, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.29 aiohttp-3.9.4 aiosignal-1.3.1 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.1.16 langchain-community-0.0.32 langchain-core-0.1.42 langchain-text-splitters-0.0.1 langsmith-0.1.47 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 orjson-3.10.0 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for grpcio: [Errno 2] No such file or directory: 'c:\\\\users\\\\anurag\\\\miniconda3\\\\envs\\\\rl_course\\\\lib\\\\site-packages\\\\grpcio-1.60.0.dist-info\\\\METADATA'\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34aa70b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Need to determine which default deprecation schedule to use. within ?? minor releases",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GooglePalm\n\u001b[0;32m      3\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAIzaSyB4NmxfcG3k9UYjvpvhqBxSUlAmI0kfF-A\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# get this free api key from https://makersuite.google.com/\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mGooglePalm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:179\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warned \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m obj \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_caller_internal():\n\u001b[0;32m    178\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[43memit_warning\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.emit_warning\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21memit_warning\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Emit the warning.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[43mwarn_deprecated\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43msince\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43malternative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_alternative\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43malternative_import\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_alternative_import\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_pending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_obj_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddendum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_addendum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremoval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremoval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Anurag\\miniconda3\\envs\\rl_course\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:342\u001b[0m, in \u001b[0;36mwarn_deprecated\u001b[1;34m(since, message, name, alternative, alternative_import, pending, obj_type, addendum, removal)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m removal:\n\u001b[0;32m    341\u001b[0m     removal \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremoval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m removal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithin ?? minor releases\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 342\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed to determine which default deprecation schedule to use. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremoval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     removal \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremoval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Need to determine which default deprecation schedule to use. within ?? minor releases"
     ]
    }
   ],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "\n",
    "api_key = 'AIzaSyB4NmxfcG3k9UYjvpvhqBxSUlAmI0kfF-A' # get this free api key from https://makersuite.google.com/\n",
    "\n",
    "llm = GooglePalm(google_api_key=api_key, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b610123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Oh, samosa, my love**\n",
      "**You are so delicious, so flaky**\n",
      "**With your filling of potatoes and peas**\n",
      "**I could eat you every day**\n"
     ]
    }
   ],
   "source": [
    "poem = llm(\"Write a 4 line poem of my love for samosa\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235a80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear [Name of Customer Service Representative],\n",
      "\n",
      "I am writing to request a refund for the [product name] that I purchased on [date]. I am not satisfied with the product because [explain why you are not satisfied].\n",
      "\n",
      "I have attached a copy of my receipt and a picture of the product. I have also included a link to the product's listing on your website.\n",
      "\n",
      "I would appreciate it if you could process my refund as soon as possible. I would like to be refunded the full amount that I paid for the product.\n",
      "\n",
      "Thank you for your time and consideration.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "essay = llm(\"write email requesting refund for electronic item\")\n",
    "print(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765695b5",
   "metadata": {},
   "source": [
    "### Now let's load data from Codebasics FAQ csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='codebasics_faqs.csv', source_column=\"prompt\")\n",
    "\n",
    "# Store the loaded data in the 'data' variable\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd45e51",
   "metadata": {},
   "source": [
    "### Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Initialize instructor embeddings using the Hugging Face model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "\n",
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762eeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fab6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.043898072093725204,\n",
       " 0.00768554350361228,\n",
       " -0.009231901727616787,\n",
       " 0.02449624426662922,\n",
       " 0.03359228000044823]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e571c0d2",
   "metadata": {},
   "source": [
    "As you can see above, embedding for a sentance \"What is your refund policy\" is a list of size 768. Looking at the numbers in this list, doesn't give any intuitive understanding of what it is but just assume that these numbers are capturing the meaning of \"What is your refund policy\". If you are curious to know about embeddings, go to youtube and search \"codebasics word embeddings\" and you will find bunch of videos with simple, intuitive explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80a28a",
   "metadata": {},
   "source": [
    "### Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c706da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=data,\n",
    "                                 embedding=instructor_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd58f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
       " Document(page_content='prompt: Will this course guarantee me a job?\\nresponse: We created a much lighter version of this course on YouTube available for free (click this link) and many people gave us feedback that they were able to fetch jobs (see testimonials). Now this paid course is at least 5x better than the YouTube course which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this course guarantee me a job?', 'row': 33}),\n",
       " Document(page_content='prompt: Will this bootcamp guarantee me a job?\\nresponse: The courses included in this bootcamp are done by 9000+ learners and many of them have secured a job which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this bootcamp guarantee me a job?', 'row': 15}),\n",
       " Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"how about job placement support?\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6b257",
   "metadata": {},
   "source": [
    "As you can see above, the retriever that was created using FAISS and hugging face embedding is now capable of pulling relavant documents from our original CSV file knowledge store. This is very powerful and it will help us further in our project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bee857",
   "metadata": {},
   "source": [
    "##### Embeddings can be created using GooglePalm too. Also for vector database you can use chromadb as well as shown below. During our experimentation, we found hugging face embeddings and FAISS to be more appropriate for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# google_palm_embeddings = GooglePalmEmbeddings(google_api_key=api_key)\n",
    "\n",
    "# from langchain.vectorstores import Chroma\n",
    "# vectordb = Chroma.from_documents(data,\n",
    "#                            embedding=google_palm_embeddings,\n",
    "#                            persist_directory='./chromadb')\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3d927",
   "metadata": {},
   "source": [
    "### Create RetrievalQA chain along with prompt template 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4842c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a4cf8",
   "metadata": {},
   "source": [
    "### We are all set 👍🏼 Let's ask some questions now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90166e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you provide job assistance and also do you provide job gurantee?',\n",
       " 'result': 'Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters. The courses included in this bootcamp are done by 9000+ learners and many of them have secured a job which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.',\n",
       " 'source_documents': [Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
       "  Document(page_content='prompt: Will this bootcamp guarantee me a job?\\nresponse: The courses included in this bootcamp are done by 9000+ learners and many of them have secured a job which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this bootcamp guarantee me a job?', 'row': 15}),\n",
       "  Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}),\n",
       "  Document(page_content='prompt: Will this course guarantee me a job?\\nresponse: We created a much lighter version of this course on YouTube available for free (click this link) and many people gave us feedback that they were able to fetch jobs (see testimonials). Now this paid course is at least 5x better than the YouTube course which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.', metadata={'source': 'Will this course guarantee me a job?', 'row': 33})]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain('Do you provide job assistance and also do you provide job gurantee?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a4e3e4",
   "metadata": {},
   "source": [
    "**As you can see above, the answer of question comes from two different FAQs within our csv file and it is able to pull those questions and merge them nicely**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dce73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you guys provide internship and also do you offer EMI payments?',\n",
       " 'result': \"Yes, we provide virtual internship and we don't offer EMI payments.\",\n",
       " 'source_documents': [Document(page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}),\n",
       "  Document(page_content='prompt: Do we have an EMI option?\\nresponse: No', metadata={'source': 'Do we have an EMI option?', 'row': 13}),\n",
       "  Document(page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.', metadata={'source': 'Do you provide any job assistance?', 'row': 11}),\n",
       "  Document(page_content='prompt: How can I contact the instructors for any doubts/support?\\nresponse: We have created every lecture with a motive to explain everything in an easy-to-understand manner. While working on these lectures you could make mistakes in steps or have some doubts. You need to commit yourself to hold patience, make efforts & diagnose the errors yourself by googling in order to become truly job ready. For any questions, that Google cannot answer or if you hit a wall - we got you covered! You can join our active discord community. which is a dedicated platform to discuss & clear your doubts with fellow learners & mentors.', metadata={'source': 'How can I contact the instructors for any doubts/support?', 'row': 5})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Do you guys provide internship and also do you offer EMI payments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48970302",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'do you have javascript course?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(page_content='prompt: I have never done programming and belong to a non-technical background. Can I take this course?\\nresponse: Yes, this is the perfect course for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in their current job or business using data.', metadata={'source': 'I have never done programming and belong to a non-technical background. Can I take this course?', 'row': 24}),\n",
       "  Document(page_content='prompt: I have never done programming in my life. Can I take this bootcamp?\\nresponse: Yes, this is the perfect bootcamp for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in your current job or business using data.', metadata={'source': 'I have never done programming in my life. Can I take this bootcamp?', 'row': 0}),\n",
       "  Document(page_content='prompt: Is there any prerequisite for taking this bootcamp ?\\nresponse: Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data analysis.', metadata={'source': 'Is there any prerequisite for taking this bootcamp ?', 'row': 2}),\n",
       "  Document(page_content='prompt: Is there any prerequisite for taking this course?\\nresponse: The only prerequisite is that you need to have a functional laptop with at least 4GB ram, internet connection and a thrill to learn data analysis.', metadata={'source': 'Is there any prerequisite for taking this course?', 'row': 35})]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"do you have javascript course?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dc6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you have plans to launch blockchain course in future?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(page_content='prompt: Will the course be upgraded when there are new features in Power BI?\\nresponse: Yes, the course will be upgraded periodically based on the new features in Power BI, and learners who have already bought this course will have free access to the upgrades.', metadata={'source': 'Will the course be upgraded when there are new features in Power BI?', 'row': 27}),\n",
       "  Document(page_content='prompt: What business concepts and domains are covered in this course?\\nresponse: We have covered the core functions such as Sales, Marketing, Finance, and Supply Chain with their fundamentals related to this course. The domain you will learn in this course is consumer goods which is projected to have more openings and high data analytics requirements at least until 2030.', metadata={'source': 'What business concepts and domains are covered in this course?', 'row': 32}),\n",
       "  Document(page_content='prompt: How can I contact the instructors for any doubts/support?\\nresponse: We have created every lecture with a motive to explain everything in an easy-to-understand manner. While working on these lectures you could make mistakes in steps or have some doubts. You need to commit yourself to hold patience, make efforts & diagnose the errors yourself by googling in order to become truly job ready. For any questions, that Google cannot answer or if you hit a wall - we got you covered! You can join our active discord community. which is a dedicated platform to discuss & clear your doubts with fellow learners & mentors.', metadata={'source': 'How can I contact the instructors for any doubts/support?', 'row': 5}),\n",
       "  Document(page_content='prompt: What is different in this course compared to hundreds of courses on the internet and free tutorials on YouTube?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for real business world problem-solving. This course is rather an experience in which you will learn Excel by solving real-life use cases in an imaginary company called AtliQ Hardware. The tutorials are very easy to understand and also have a lot of fun elements into them so that you don’t get bored ??', metadata={'source': 'What is different in this course compared to hundreds of courses on the internet and free tutorials on YouTube?', 'row': 18})]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Do you have plans to launch blockchain course in future?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c35c2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'should I learn power bi or tableau?',\n",
       " 'result': 'This is a contextual question. If you are talking about a pure visualization tool Tableau is slightly better. Data connectors, modeling and transformation features are available in both. However, factually speaking Power BI is cheaper and offers tighter integration with the Microsoft environment. Since most companies use excel & Microsoft tools they start with Power BI or move towards Power BI for seamless integration with other Microsoft tools (called as Power platform). This makes the job openings grow at a much higher rate on Power BI and Power Platform. Also, Power BI has been leading the Gartner’s magic quadrant in BI for the last few years as the industry leader.',\n",
       " 'source_documents': [Document(page_content='prompt: Power BI or Tableau which one is better?\\nresponse: This is a contextual question. If you are talking about a pure visualization tool Tableau is slightly better. Data connectors, modeling and transformation features are available in both. However, factually speaking Power BI is cheaper and offers tighter integration with the Microsoft environment. Since most companies use excel & Microsoft tools they start with Power BI or move towards Power BI for seamless integration with other Microsoft tools (called as Power platform). This makes the job openings grow at a much higher rate on Power BI and Power Platform. Also, Power BI has been leading the Gartner’s magic quadrant in BI for the last few years as the industry leader.', metadata={'source': '\\nPower BI or Tableau which one is better?', 'row': 29}),\n",
       "  Document(page_content='prompt: What is different in this course from thousands of other Power BI courses available online?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for the real business world. This course is rather an experience in which you will learn how to use Power BI & other non-technical skills to solve a real-life business problem using analytics. Here you focus on solving a business problem and in that process learn how Power BI can be used as a tool. This is how you will do the work when you start working as a data analyst/ Business analyst/ Power BI developer in the industry. This course will prepare you for not just fetching the job but, shine in it & grow further.', metadata={'source': 'What is different in this course from thousands of other Power BI courses available online?', 'row': 36}),\n",
       "  Document(page_content='prompt: I already know basic Power BI, what benefit do I get by taking this course?\\nresponse: This course is taught through a true end-to-end project in a Consumer goods company involving all the steps mimicking the real business environment, so you will learn how to execute end-to-end projects Power BI projects successfully along with the business fundamentals. You will learn a lot of extra things such as Project management tools, effective communication techniques & organizational nuances.', metadata={'source': 'I already know basic Power BI, what benefit do I get by taking this course?', 'row': 37}),\n",
       "  Document(page_content='prompt: Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?\\nresponse: Yes, this bootcamp will certainly help because we cover the majority of the skills measured in these exams. However, please be informed that this course focuses on Job ready aspects and not on all aspects required to clear the exams. In addition to this course, you might need to visit the official learning material designed by Microsoft which is available for free on their website.', metadata={'source': 'Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?', 'row': 12})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"should I learn power bi or tableau?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054c5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"I've a MAC computer. Can I use powerbi on it?\",\n",
       " 'result': 'response: Hi\\n\\nPower BI desktop works only in Windows OS. Please look into the system requirements section on this page. However, you can use a virtual machine to install and work with Power BI in other Operating systems.',\n",
       " 'source_documents': [Document(page_content='prompt: How can I use PowerBI on my Mac system?\\nresponse: Hi\\n\\nYou can use VirtualBox to create a virtual machine and install Windows on it. This will allow you to run Power BI and Excel on your Mac.\\n\\nIf you\\'re not familiar with setting up a virtual machine, there are many resources available on YouTube that can guide you through the process. Simply search for \"installing virtual machines\" and you\\'ll find plenty of helpful videos.\\n\\nBest of luck with your studies!', metadata={'source': 'How can I use PowerBI on my Mac system?', 'row': 44}),\n",
       "  Document(page_content='prompt: Does Power BI work in Mac OS/Ubuntu?\\nresponse: Power BI desktop works only in Windows OS. Please look into the system requirements section on this page. However, you can use a virtual machine to install and work with Power BI in other Operating systems.', metadata={'source': 'Does Power BI work in Mac OS/Ubuntu?', 'row': 31}),\n",
       "  Document(page_content='prompt: i am unable to import data from mysql in power bi ,connector issue is coming continuously i have done all steps according to connector pdf still its not resolving please guide\\nresponse: Please refer to this thread: https://discord.com/channels/1090613684163850280/1107992760105054238/1107993007606730802', metadata={'source': 'i am unable to import data from mysql in power bi ,connector issue is coming continuously i have done all steps according to connector pdf still its not resolving please guide', 'row': 54}),\n",
       "  Document(page_content='prompt: Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?\\nresponse: Yes, this bootcamp will certainly help because we cover the majority of the skills measured in these exams. However, please be informed that this course focuses on Job ready aspects and not on all aspects required to clear the exams. In addition to this course, you might need to visit the official learning material designed by Microsoft which is available for free on their website.', metadata={'source': 'Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?', 'row': 12})]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"I've a MAC computer. Can I use powerbi on it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain(\"I don't see power pivot. how can I enable it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6539e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain(\"What is the price of your machine learning course?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_course",
   "language": "python",
   "name": "rl_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
